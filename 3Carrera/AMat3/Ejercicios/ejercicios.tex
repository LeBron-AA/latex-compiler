\documentclass[12pt,a4paper]{article}

% Paquetes básicos
\usepackage[x11names]{xcolor}
\usepackage[utf8]{inputenc}
\usepackage{mathtools, amssymb, amsthm}
\usepackage{changepage}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{etoolbox}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{tcolorbox}
\tcbuselibrary{skins, breakable}
\usepackage{titlesec}
\usepackage{tikz} % core TikZ
\usetikzlibrary{matrix}

% Margins
%\geometry{left=3cm,right=3cm,top=2.5cm,bottom=2.5cm}

% Custom operators
\newcommand{\card}{\operatorname{card}}
\newcommand{\muae}{\overset{\mu-a.e.}{=}}

% Implication box setup
\tcbset{Implication-number/.style={
  enhanced,
  boxsep=2pt,
  colback=white,
  frame hidden,
  sharp corners,
  left=2pt, right=2pt, top=1pt, bottom=1pt,
  underlay={
    \draw[line width=0.5pt] (frame.south west) -- ([xshift=-133mm]frame.south east); % línea horizontal
    \draw[line width=0.5pt] ([xshift=-133mm]frame.north east) -- ([xshift=-133mm]frame.south east); % línea vertical
  }
}}

\tcbset{Implication-number-ds/.style={
  enhanced,
  boxsep=2pt,
  colback=white,
  frame hidden,
  sharp corners,
  left=2pt, right=2pt, top=1pt, bottom=1pt,
  underlay={
    \draw[line width=0.5pt] ([yshift=5mm]frame.south west) -- ([xshift=-133mm, yshift=5mm]frame.south east); % línea horizontal
    \draw[line width=0.5pt] ([xshift=-133mm, yshift=-3mm]frame.north east) -- ([xshift=-133mm, yshift=5mm]frame.south east); % línea vertical
  }
}}

\tcbset{Subset-contingency/.style={
  enhanced,
  boxsep=2pt,
  colback=white,
  frame hidden,
  sharp corners,
  left=2pt, right=2pt, top=1pt, bottom=1pt,
  underlay={
    \draw[line width=0.5pt] (frame.south west) -- ([xshift=-140mm]frame.south east); % línea horizontal
    \draw[line width=0.5pt] ([xshift=-140mm]frame.north east) -- ([xshift=-140mm]frame.south east); % línea vertical
  }
}}

% Useful commands
\renewcommand{\contentsname}{Contenidos}

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}

\newcommand{\smallcup}{\mathop{\cup}\limits}
\newcommand{\smallcap}{\mathop{\cap}\limits}
\newcommand{\smallsum}{\mathop{\sum}\limits}
\newcommand{\smallprod}{\mathop{\prod}\limits}

\newcommand{\linf}[1]{\displaystyle{\mathop{\underline{\lim}}_{#1}}}
\newcommand{\mlim}[1]{\displaystyle{\lim_{#1}}}

%Integral de Lebesgue con patas
\newcommand{\lbint}{\mathop{\int_{\!\!\!\!\!|\!}^{\!|\!}}}

% ----- Custom counters and counter commands -----
% Custom counter hierarchy
\newcounter{unit}[section]
\newcounter{chapter}[unit]
\makeatletter
\@addtoreset{subsubsection}{chapter}
\makeatother

\renewcommand{\theunit}{\arabic{unit}}
\renewcommand{\thechapter}{\arabic{chapter}}
\renewcommand{\thesubsubsection}{\theunit.\thechapter.\arabic{subsubsection}}

% Custom content hierarchy behavior
\newcommand{\chapter}[1]{
    \refstepcounter{chapter}
    \subsection*{\Large{\S \thechapter. #1}}
    \addcontentsline{toc}{subsection}{\thechapter. #1}
}
\newcommand{\unit}[1]{
    \refstepcounter{unit}
    \section*{\Huge{\Roman{unit} #1}}
    \addcontentsline{toc}{section}{\Roman{unit} #1}
}

\newcommand{\result}[1]{%
  \subsubsection{#1}%
  \label{result:\thesubsubsection}
}
  
\titleformat{\subsubsection}
    {\normalfont\large\bfseries} % mismo tamaño que \subsection
    {\thesubsubsection}{1em}{}
  
%---- Custom proof commands-----
\newcommand{\dem}{
    \noindent \underline{\textbf{Demostración:}}
}
\newcommand{\nota}{
    \noindent \underline{\textbf{Nota:}}
}
% ----------------------------------------

\title{Análisis Matemático III}
\author{Javier Ortín Rodenas}
\date{Hoja de ejercicios}

\begin{document}
\onehalfspacing

\maketitle
\newpage
\tableofcontents
\newpage
\unit{Teoría de la medida e Integral de Lebesgue}
\chapter{Medida exterior en \texorpdfstring{$\R^N$}{R\^N}}
\result{Ejercicio 5}
a) Sea $A = \Q \cap [0,1]$, demuestra que todo cubrimiento finito de $A$ formado por intervalos abiertos tiene longitud total mayor o igual a 1.

\vspace{2mm}
\dem 
Sea $\{I_i\}_{i=1}^n$ un recubrimiento por intervalos abiertos de $A$, con cada $I_i = (a_i, b_i)$ con $a_i < b_i$. Definimos el siguiente conjunto auxiliar:
$$\mathcal{A} := \{0,1\} \cup \Big([0,1]\cap \big\{a_i,b_i : i \in \{1,\ldots,n\}\big\}\Big) $$
Este conjunto contiene a los extremos de los $I_i$ que se encuentren entre $0$ y $1$. Al haber un número finito de intervalos, tenemos que $\mathcal{A}$ es finito, pudiendo ordenarlo como sigue:
\begin{align*}
    \mathcal{A} = \{x_j\}_{j=0}^m &&
    x_0 = a < x_1 < \ldots < x_m = b &&
    \text{ para cierto } m \in \N
\end{align*}

Al estar en un caso finito, la unión de las clausuras es la clausura de las uniones. Por contención de las clausuras, se tiene:
\begin{flalign*}
    A \subseteq \bigcup_{i=1}^n I_i \Rightarrow \overline{A} = [0, 1] \cap \overline{\Q} = [0,1] \subseteq \overline{\bigcup_{i=1}^n I_i} = \bigcup_{i=1}^n \overline{I_i}
\end{flalign*}
Sea $j \in \{1,\ldots, m\}$ cualquiera, tenemos que $x_j \in [0,1] \subseteq \smallcup_{i=1}^n \overline{I_i}$ luego $\exists k \in \{1,\ldots,n\}$ tal que $x_j \in [a_k, b_k]$. Veamos que $[x_{j-1}, x_j] \subseteq [a_k, b_k]$ también.
Ambos conjuntos son cerrados y conexos con intersección no vacía. Por tanto, su intersección ha de ser conexa, cerrada y no vacía (es decir, un intervalo cerrado). Será de la forma $[u, x_j]$ con $u = \min \{a_k, x_{j-1}\}$. De tenerse $u \neq x_{j-1}$, se cumpliría $x_{j-1} < a_k < x_{j}$, lo que contradice la ordenación establecida para $\mathcal{A}$.

De este modo, como $v_1(I_i) = v_1(\overline{I_i}) \hspace{2mm} \forall i \in \{1,\ldots, n\}$, se cumple:
\begin{flalign*}
    1 = v_1([0,1]) = \sum_{j=1}^m v_1 (x_{j-1}, x_j) \leq \sum_{i=1}^n v_1(\overline{I_i}) = \sum_{i=1}^n v_1(I_i)
\end{flalign*}

\vspace{4mm}
b) Deduce del apartado anterior que $A$ no es compacto.

\vspace{2mm}
\dem Veamos que hay un recubrimiento de $A$ del que no se puede extraer un subrecubrimiento finito. Para ello basta dar un recubrimiento de $A$ por intervalos abiertos tales que la suma de sus medidas sea menor a $1$. Como $\Q$ es numerable, $A$ también lo es. Sea $(a_n)_{n\in\N}$ una enumeración cualquiera de $A$, definimos los siguientes intervalos:
\begin{align*}
    I_n = (a_n - \frac{1}{2^{n+2}}, a_n + \frac{1}{2^{n+2}}) &&
    \text{ luego } A \subseteq \smallcup_{i\in\N}I_i \text{ con } \sum_{i=1}^\infty v_1(I_i) = \sum_{n=1}^{\infty} \frac{1}{2^{n+1}} = \frac{1}{2}
\end{align*}

\hspace{4mm} \noindent
c) Demuestra que la siguiente aplicación $m$ definida sobre $\mathfrak{B}_N$ no es una medida:
$$ m(A) = \inf \left\{\sum{i=1}^n v(I_i) : \smallcup_{i=1}^n I_i \supseteq A \hspace{1mm} \text{ con cada } I_i \text{ cubo abierto en} \R^N \right\}$$

\vspace{2mm}
\dem \newline \noindent En caso de serlo, para $\{E_i\}_{i\in\N} \subseteq \mathfrak{B}_N$ con $i \neq j \Rightarrow E_i \cap E_j = \varnothing$ se cumpliría:
$$ m\left(\smallcup_{i\in\N} E_i\right) = \sum_{i\in\N} \mu(E_i)$$
Todo conjunto unipuntual ${a}$ con $a \in \R^N$ está en $\mathfrak{B}_N$ pues se puede expresar como un intervalo cerrado degenerado. Por tando, todo conjunto numerable está también en $\mathfrak{B}_N$. Consideramos el conjunto $A^N \subseteq [0,1]^N \in \mathfrak{B}_N$. Razonando como en el apartado anterior, todo cubrimiento finito de $A^N$ por cubos ha de tener suma de volúmenes mayor o igual a $1$, luego $m(A^N) = 1$. No obstante, podemos expresar $A^N$ como unión numerable de conjuntos unipuntuales disjuntos, teniendo cada uno de ellos $m(\{b_n\}) = 0$ para $(b_n)_n$ una enumeración de $A^N$.

\vspace{4mm}
\result{Ejercicio 6}
Demuestra que existe un conjunto abierto $O$ en $\R$ y un $\varepsilon > 0$ tal que para cualquier recubrimiento finito de $O$ formado por intervalos abiertos, $\{J_i\}_{i=1}^m$ se cumple $\mu(\smallcup_{i=1}^n J_i \setminus O) > \varepsilon$.
\vspace{4mm}

\dem \newline \indent Para cada $n \in \N$ tomamos $I_n = (n - \frac{1}{3}, n + \frac{1}{3})$. Consideramos el abierto $O = \smallcup_{i\in\N} I_i$. Sea $\{J_i\}_{i=1}^m$ un recubrimiento finito de $O$ por intervalos abiertos. Al ser $O$ no acotado, tiene que haber cierto $k \in \{1, \ldots, m\}$ tal que $J_k$ contiene a infinitos intervalos $I_n$. Dados dos de estos intervalos consecutivos, la distancia entre el extremo derecho del primero y el extremo izquierdo del segundo viene dada por:
$$\left(n+1 - \frac{1}{3}\right) - \left(n + \frac{1}{3}\right) = 1 - \frac{2}{3} = \frac{1}{3}$$
Por tanto, $J_k \setminus O$ ha de contener infinitos intervalos disjuntos de longitud $\frac{1}{3}$ luego tiene medida infinita. Se cumple el resultado para $\varepsilon > 0$ cualquiera.

%CAMBIO DE HOJA
\newpage
\chapter{Conjuntos medibles}
\vspace{2mm}\result{Ejercicio 2}
\hspace{3mm} Sea $A \in \mathfrak{M}_N$ con $\mu(A) < \infty$. Sea $\varepsilon > 0$, demuestra que existe $K \subseteq A$ conjunto compacto tal que $\mu(A \setminus K) < \varepsilon$. ¿Se cumple también si $\mu(A) = \infty$?
\vspace{2mm}
\dem \newline \indent Sea $A_n = A \cap [-n,n]$, tenemos que $(A_n)_n$ es una sucesión creciente de conjuntos medible que tiene como unión el conjunto $A$. Por tanto, se tiene
$$\infty > \mu(A) = \mu(\smallcup_{i\in\N} A_i) = \lim_{n} \mu(A_n)$$
Por tanto, existe cierto $n_0 \in \N$ tal que $\mu(A) - \mu(A_{n_0}) = \mu(A \setminus A_{n_0}) < \frac{\varepsilon}{2}$. Hemos podido despejar sin indeterminaciones al estar en un caso de medida finita.

\vspace{2mm} Como $A_{n_0}$ es medible, sabemos que existe un conjunto cerrado $C \subseteq A_{n_0}$ tal que $\mu(A_{n_0} \setminus C) < \frac{\varepsilon}{2}$. Al ser $A_{n_0}$ acotado y estar $C$ contenido en él, tenemos que $C$ es compacto. Por todo lo anterior:
$$\mu(A \setminus C) = \mu(A) - \mu(C) = \mu(A) - \mu(A_{n_0}) + \mu(A_{n_0}) - \mu(C) < \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon$$

\vspace{2mm} En cambio, para el caso infinito, no tiene por qué cumplirse. Sea $A = \R^N$, en la topología usual, los conjuntos compactos son aquellos cerrados y acotados. En espacios métricos, un conjunto es acotado sii existe una bola de radio finito que lo contiene. Por el Teorema de Hausdorff, podemos considerar la norma $||\cdot||_1$, que tiene como bolas a los cubos. Por tanto, todo compacto $K$ va a estar contenido en una bola de radio finito; es decir, en un cubo de volumen (medida) finito. Despejando:
$$\mu(\R^N \setminus K) = \mu(\R^N) - \mu(K) = \infty - \mu(K) = \infty > \varepsilon \hspace{2mm} \forall \varepsilon \in (0, +\infty) $$

\newpage
\result{Ejercicio 3}
\hspace{3mm} Sea $A \in \mathfrak{M}_N$, ¿son ciertas las siguientes implicaciones?
\begin{enumerate}[label=\roman*)]
    \item $\mathring{A} \neq \varnothing \Rightarrow \mu(A) = 0$.
    \item $\mathring{A} = \varnothing \Rightarrow \mu(A) = 0$.
    \item $A$ abierto $\Rightarrow \mu(\mathop{Fr.} A) = 0$.
    \item $A$ no numerables $\Rightarrow \mu(A) > 0$.
\end{enumerate}
\vspace{2mm} \dem \newline \noindent $\romannumeral 1)$ Falso: basta considerar $\R^N$.

\vspace{2mm} \noindent $\romannumeral 2)$ Falso: basta considerar $\R \setminus \Q$ (o cualquier variante $N$-dimensional).

\vspace{2mm} \noindent $\romannumeral 3)$ Utilizaremos una variación del conjunto de Cantor. En cada iteración ``eliminamos'' la parte central de longitud $\frac{1}{4^n}$ de cada intervalo. Veamos ejemplos de algunas iteraciones:
\\[-2ex]
\begin{align*}
  &&\Big[0,1\Big]&&
\end{align*}
\begin{align*}
  \left[0, \frac{3}{8}\right] && \left[\frac{5}{8}, 1\right]
\end{align*}
\begin{align*}
  \left[0, \frac{1}{8}\right] && \left[\frac{1}{4}, \frac{3}{8}\right] && \left[\frac{5}{8}, \frac{3}{4}\right] && \left[\frac{7}{8}, 1\right]
\end{align*}
En la $n$-ésima iteración eliminamos $2^{n-1}$ intervalos cada uno de longitud $\frac{1}{4^n}$. Como los intervalos quitados son disjuntos, podemos calcular su medida total como la suma de las longitudes quitadas. Sea $L_n$ la longitud quitada en la $n$-ésima iteración,
\begin{align*}
  L_n = 2^{n-1} \cdot \frac{1}{4^n} = \frac{1}{2^n+1} &&
  \sum_{n=1}^\infty L_n = \frac{1}{2}
\end{align*}
Considerando $O = (0,1)\setminus C$ para $C$ la intersección de todas las iteraciones, tenemos que la frontera de $O$ es $C$, que tiene como medida $1 - \frac{1}{2} = \frac{1}{2}$.

\vspace{2mm}
$\romannumeral 4)$ Falso: basta considerar $\R \setminus \Q$.

\vspace{4mm}
\result{Ejercicio 5}
Demuestra que para cada $A \in \mathfrak{M}_1$ con $\mu(A) < \infty$ y cada $\varepsilon > 0$ existe una colección finita de intervalos disjuntos y abiertos $\{I_i\}_{i=1}^m$ tales que:
\begin{align*}
    \mu\left(A \Delta \smallcup_{i=1}^m I_i\right) < \varepsilon && \text{ con } A \Delta B = (A \setminus B) \cup (B \setminus A)
\end{align*}
\vspace{2mm} \dem \newline \vspace{2mm} \indent Por ser $A$ un conjunto medible, es de la forma $A = (\smallcap_{i\in\N} G_i) \setminus M$ para $(G_i)_{i\in\N}$ una sucesión decreciente de abiertos de $\R^N$ y $M$ un conjunto de medida nula.
\vspace{2mm} \newline \indent Como $M$ no interfiere en la medida, tenemos que $\mu(A) = \mlim{n} \hspace{1mm} \mu(G_n) < \infty$. Por definición de límite, $\exists \hspace{1mm} n_0 \in \N$ tal que $\mu(G_{n_0} \setminus A) = \mu(G_{n_0}) - \mu(A) < \frac{\varepsilon}{2}$. Hemos podido pasar a la medida de la diferencia de conjuntos al estar en el caso de medida finita. Por simplicidad, denotaremos $G = G_{n_0}$.
\vspace{2mm} \newline Al ser $G$ abierto, podemos expresarlo como unión numerable de bolas abiertas $\{J_i\}_{i\in\N}$. Para cada $n \in \N$ tomamos $O_n = \smallcup_{i=1}^n J_i$. Tenemos que $(O_n) _n$ es una sucesión de conjuntos crecientes cuya unión es igual a $G$. Razonando como en el caso anterior:
\begin{align*}
    \mu(G) = \mu(\smallcup_{i\in\N} O_i) = \lim_n \mu(O_n) \Rightarrow \exists \hspace{1mm} n_1 \in \N : \mu(G \setminus O_{n_1}) < \frac{\varepsilon}{2}
\end{align*}
\indent Tomamos como $\{I_i\}_{i=1}^n$ las componentes conexas de $O_{n_1}$, que son disjuntas e intervalos (en $\R$ los conjuntos conexos son precisamente los intervalos). Además, hay un número finito de ellas (en el peor de los casos, cada $J_i$ con $1\leq i \leq n_1$ sería una componente conexa). De este modo, aplicando la monotonía de la medida:
\begin{flalign*}
    \mu\left(A \setminus \smallcup_{i=1}^n I_i\right) \leq \mu\left(G \setminus \smallcup_{i=1}^n I_i\right) < \frac{\varepsilon}{2} \\[2ex]
    \mu\left(\smallcup_{i=1}^n I_i \setminus A \right) \leq \mu\left(G \setminus A\right) < \frac{\varepsilon}{2}
\end{flalign*}
Sumando se llega al resultado.

%CAMBIO DE HOJA
\newpage
\chapter{Funciones medibles}
\vspace{2mm}
\result{Ejercicio 5}
\hspace{3mm} Sea $f : \R^N \longrightarrow \R$ uniformemente continua y acotada, demuestra que la siguiente función es medible:
\begin{align*}
    \varphi : \R^N \longrightarrow \R &&
    t \longmapsto \varphi(t) = \sup_{x\in\R^N} |f(x+t) - f(x)|
\end{align*}

\vspace{5mm}
\dem

\vspace{2mm} Por ser $f$ acotada, tenemos que $\exists \hspace{1mm} M \in \R : |f(x)|\leq M \forall x \in \R^N$. De este modo, sean $x, y \in \R^N$, tenemos:
$$|f(x) - f(y) | \leq |f(x)| + |f(y)| \leq M + M = 2M$$
Por tanto, concluimos que $\varphi$ es también acotada. Veamos que es medible por la definición.

\vspace{4mm}
Sea $K := \displaystyle \sup_{t\in\R^N}\varphi(t)$, como $\varphi$ solo toma valores no negativos tenemos que:
\begin{align*}
    \varphi^-1\Big((-\infty, 0]\Big) = \varnothing \in \mathfrak{M}_N &&
    \varphi^-1\Big((-\infty, K]\Big) = \R^N \in \mathfrak{M}_N 
\end{align*}
Fijando ahora $\varepsilon \in (0, K)$ cualquiera, veamos que $\varphi\Big((-\infty, \varepsilon]\Big)$ es medible. Al ser $f$ uniformemente continua por hipótesis, tenemos que para el $\varepsilon$ fijado existe un $\delta > 0$ tal que:
$$|| x - y|| < \delta \Rightarrow |f(x) - f(y)| < \varepsilon \hspace{4mm} \forall x,y \in \R^N$$

Podemos reescribir $y = x + t$ para $t = y - x \in \R^N$. De este modo; sea $t \in \R^N$, se tiene:
$$||t|| < \delta \Rightarrow |f(x+t) - f(x)| < \varepsilon$$
\indent Se cumple la condición para todo $x$ de $\R^N$. Al tomar supremos, la desigualdad pasa a ser no estricta, y el término mayorado por $\varepsilon$ se corresponde con $\varphi(t)$ por definición:
$$||t|| < \delta \Rightarrow \varphi(t) = \sup_{x\in\R^N} |f(x+t) - f(x)| \leq \varepsilon $$
Así, sea $(t_n)_n$ una sucesión que tiende al origen, ha de "atravesar" todos las bolas de radio $\delta$ asociado a valores de $\varepsilon$ arbitrariamente pequeños. Por tanto, podemos concluir que $\phi$ es continua en el origen.

\vspace{4mm}
Sean $s,t \in \R^N$ cualesquiera, se cumple:
\begin{flalign*}
    \varphi(t) &= \sup_{x\in\R^N} |f(x+t) - f(x)| \leq \sup_{x\in\R^N} |f(x+t) - f(x+s)|+ |f(x+s) - f(x)| \leq\\
    &\leq \sup_{x\in\R^N}|f(x + t) - f(x + s)| + \sup_{y\in\R^N}|f(y+s) - f(y)| \overset{z = x + s}{=} \sup_{z\in\R^N}| f\big(z + (t-s) \big)- f(z)| + \varphi(s)
\end{flalign*}
Despejando, obtenemos $0 \leq \varphi(t) - \varphi(s) \leq \varphi(t-s) \xrightarrow{s\to t} \varphi(0) = 0$.

\vspace{4mm} Por todo lo anterior, concluimos que $\varphi$ es continua y acotada, luego es medible en $\mathfrak{B}_N$ y en $\mathfrak{M}_N$

\newpage
\unit{Series de Fourier}
\chapter{Sistemas ortogonales}
\result{Ejercicio 1}
\hspace{3mm}  Una colección finita de funciones $(\varphi_k)_{k=0}^n$ (todas con dominio $I$) se dice \emph{linealmente independiente} si
\[
\sum_{k=0}^n \lambda_k \varphi_k \equiv 0 \quad \iff \quad \lambda_k=0\ \text{para todo }0\le k\le n.
\]
\indent Una colección de funciones $(\varphi_k)_{k=0}^\infty$ se dice \emph{linealmente independiente} si todo subconjunto finito suyo es linealmente independiente. Prueba que todo sistema ortonormal sobre $I$ es linealmente independiente.

\vspace{4mm} \dem \vspace{2mm} \newline \indent
Sea $\{\varphi_n\}_{n\in\N}$ un sistema ortonormal con dominio $I$. Sea $A := \{a_1, \ldots, a_n\} \subseteq \N$ finito. Supongamos que se cumple $\smallsum_{k=1}^n \lambda_k \varphi_{a_k} \equiv 0$.

\vspace{2mm} Fijado $j \in \{q,\ldots, n\}$ cualquiera, tenemos:
\begin{flalign*}
    \langle \varphi_{a_j}, 0\rangle = 0 = \left\langle \varphi_{a_j}, \sum_{k=1}^n\lambda_k \varphi_{a_k} \right\rangle = \sum_{k=1}^{n}\lambda_k \langle \varphi_{a_j}, \varphi_{a_k}\rangle = \lambda_j
\end{flalign*}
La última igualdad se deduce como aplicación directa de la ortonormalidad. Como el $j$ escogido fue arbitrario, concluimos que el sistema es linealmente independiente.

\vspace{6mm}  
\result{Ejercicio 2}
Proceso de ortogonalización de Gram-Schmidt. Sea $(f_n)_{n=0}^\infty$ un sistema de funciones linealmente independientes en $L^2(I)$. Sea la sucesión de funciones dada recursivamente por
\[
g_0:=f_0,\qquad 
g_{n+1}:=f_{n+1}-\sum_{k=0}^n\frac{\langle f_{n+1},g_k\rangle}{\langle g_k,g_k\rangle}\,g_k.
\]
Demuestra que $(g_n)_{n=0}^\infty$ es un sistema ortogonal y que
\[
\operatorname{span}\{f_k\}_{k=0}^n=\operatorname{span}\{g_k\}_{k=0}^n
\]
para todo $n$.

\vspace{4mm} \dem Aplicaremos inducción.
\vspace{2mm} \newline \indent En primer lugar, probaremos que $\{g_k\}_{k=0}^n$ es ortogonal para todo $n\in\N$. Comprobemos el caso base:
\begin{flalign*}
    g_1 = f_1 - \frac{\langle f_1, g_0\rangle}{\langle g_0, g_0\rangle}g_0 = f_1 -\frac{\langle f_1, f_0\rangle}{\langle f_0, f_0\rangle}f_0
\end{flalign*}
Aplicando la linealidad del producto interno,
\begin{flalign*}
    \langle g_1, g_0\rangle = \langle f_1,f_0\rangle - \frac{\langle f_1,f_0\rangle}{\langle f_0,f_0\rangle} \cdot \langle f_0, f_0\rangle = 0
\end{flalign*}
Supongamos que la hipótesis es cierta para $n$ y comprobemos que se cumple para $n+1$. Sea $j \in \{1,\ldots,n\}$, aplicando de nuevo la linealidad,
\begin{flalign*}
  g_{n+1} &= f_{n+1} - \sum_{k=0}^{n}\frac{\langle f_{n+1}, g_k\rangle}{\langle g_k, g_k\rangle} g_k \Rightarrow \langle g_{n+1}, g_j\rangle = \langle f_{n+1}, g_j\rangle - \sum_{k=0}^{n}\frac{\langle f_{n+1},g_k\rangle}{\langle g_k,g_k\rangle}\cdot \langle g_k, g_j\rangle =&&\\
  &= \langle f_{n+1}, g_j\rangle - \frac{\langle f_{n+1},g_j\rangle}{\langle g_j,g_j\rangle}\cdot \langle g_j, g_j\rangle = 0
\end{flalign*}

\vspace{2mm} Tenemos la ortogonalidad. Queda ver que se respetan las clausuras.

\vspace{2mm}
Puesto que $f_0$ = $g_0$, tenemos el caso base. Supongamos que se cumple para $n$ y veamos que es cierto para $n+1$.
\begin{flalign*}
  \hspace{3mm} g_{n+1} &= f_{n+1} - \sum_{k=0}^{n}\frac{\langle f_{n+1}, g_k\rangle}{\langle g_k, g_k\rangle} g_k \in K \langle g_0, \ldots, g_n, f_{n+1} \rangle = K \langle f_0, \ldots,f_n, f_{n+1}\rangle &&\\[1ex]
  \hspace{3mm} f_{n+1} &= g_{n+1} + \sum_{k=0}^{n}\frac{\langle f_{n+1}, g_k\rangle}{\langle g_k, g_k\rangle} g_k \in K \langle g_0, \ldots, g_n, g_{n+1} \rangle &&
\end{flalign*}
Tenemos que $K\langle g_0, \ldots, g_n, g_{n+1} \rangle = K \langle f_0, \ldots, f_n, f_{n+1} \rangle$ por doble contenido.

\vspace{6mm}
\result{Ejercicio 3}
\hspace{3mm} Demuestra que el sistema de polinomios $(x^n)_{n=0}^\infty$ es linealmente independiente. Calcula las cuatro primeras funciones que se obtienen al aplicar el proceso de ortonormalización de Gram--Schmidt sobre el intervalo $[-1,1]$ (De este procedimiento pueden obtenerse los llamados \emph{polinomios de Legendre}).

\vspace{4mm} \dem \vspace{2mm} \newline \indent
Todo polinomio no nulo puede tener a lo sumo un número de raíces igual a su grado. Por tanto, sea $n\in\N$ cualquiera,
$$\alpha_0 \cdot 1 + \alpha_1 x + \alpha_2 x^2 + \ldots + \alpha_n x^n \equiv 0 \iff \alpha_i = 0 \hspace{2mm} \forall i \in \{0,\ldots, n\}$$
El sistema es linealmente independiente por definición. Apliquemos ahora el proceso de Gram-Schmidt.
\begin{flalign*}
  \hspace{3mm}& \int_{-1}^1 x\cdot 1 \,dx = \left[\frac{x^2}{2}\right]_{-1}^1 = 0 \Rightarrow p_1 = x - \frac{\langle x,1\rangle}{\langle 1,1\rangle} = x &&
\end{flalign*}
\begin{flalign*}
  \int_{-1}^1 x &\cdot x^2 \,dx = \left[\frac{x^4}{4}\right]_{-1}^{^1} \hspace{-4mm} = 0 \hspace{6ex}
  \int_{-1}^1 x^2 \cdot 1 \,dx = \frac{2}{3} \hspace{6ex}
  &p_2 = x^2 -\frac{2}{3 \langle 1,1\rangle}1 - \frac{0}{\langle x,x\rangle}x = x^2 - \frac{1}{3} &&
\end{flalign*}
\begin{flalign*}
    &\int_{-1}^{1} x^3\left(x^2 - \frac{1}{3}\right) \,dx = 0 = \int_{-1}^{1}x^3 \cdot 1\,dx &&\\[1ex]
    &\int_{-1}^1 x^3 \cdot x \,dx = \frac{2}{5} \\[1ex]
    &p_3 = x^3 - \frac{2}{5 \langle x,x\rangle}x = x^3 - \frac{2}{5}\cdot \frac{3}{2}x = x^3 - \frac{3}{5}x
\end{flalign*}
El proceso de Gram-Schmidt no garantiza la ortonormalidad, sino únicamente la ortogonalidad. Tras normalizar, se obtienen los siguientes vectores.
$$\left\{\frac{1}{\sqrt{2}}, \hspace{1mm} \sqrt{\frac{3}{2}} x, \hspace{1mm} \sqrt{\frac{45}{8}}\left(x^2 - \frac{1}{3}\right), \hspace{1mm} \sqrt{\frac{175}{8}}\left(x^3 - \frac{3}{5}x\right)\right\}$$

\vspace{6mm}
\result{Ejercicio 4}
\hspace{3mm} Sea \(I:=[0,2\pi]\) y sea \((\varphi_n)_{n=0}^\infty\) un sistema ortonormal en \(\mathcal L_2(I)\). Demuestra los siguientes apartados:

\begin{enumerate}[label=(\arabic*)]
\item los siguientes enunciados son equivalentes:
  \begin{enumerate}[label=(\alph*)]
  \item dadas \(f\) y \(g\) en \(\mathcal L_2(I)\), \(\langle f,\varphi_n\rangle=\langle g,\varphi_n\rangle\) para todo \(n\) implica $f \muae g$.
  \item dada \(f\in\mathcal L_2(I)\), \(\langle f,\varphi_n\rangle=0\) para todo \(n\) implica \(f\muae 0\).
  \item Si \(T\) es un sistema ortonormal que contiene a \((\varphi_n)_{n=0}^\infty\), entonces \(T=(\varphi_n)_{n=0}^\infty\) (en cuyo caso se dice que \((\varphi_n)_{n=0}^\infty\) es un sistema ortonormal maximal).
  \end{enumerate}

\item Supón que \((\varphi_n)_{n=0}^\infty\) satisface el enunciado (c). Demuestra que toda \(f\in\mathcal L_2(I)\) verifica
\[
\Big\|\,f-\sum_{k=0}^n\langle f,\varphi_k\rangle\varphi_k\,\Big\|_2\;\xrightarrow[n\to\infty]{}\;0.
\]
¿Es \((\varphi_n)_{n=0}^\infty\) una base (algebraica, también llamada de Hämel) del espacio vectorial \(\mathcal L_2(I)\)?

\item Demuestra que los sistemas
\[
\left(\frac{1}{\sqrt{2\pi}},\;\frac{\cos x}{\sqrt{\pi}},\;\frac{\sin x}{\sqrt{\pi}},\;\frac{\cos 2x}{\sqrt{\pi}},\;\frac{\sin 2x}{\sqrt{\pi}},\ldots\right)
\]
y \(\bigl(e^{inx}/\sqrt{2\pi}\bigr)_{n\in\mathbb Z}\) son sistemas ortonormales maximales.
\end{enumerate}

\vspace{4mm} \dem \vspace{2mm} \newline \noindent
(1) Veamos que se cumplen todas las implicaciones:
\begin{tcolorbox}[Implication-number]
    $a \Rightarrow b$  \hspace{3mm} Se tiene al considerar $g = 0$.
\end{tcolorbox}
\begin{tcolorbox}[Implication-number]
    $b \Rightarrow c$  \hspace{3mm} Supongamos que existe $f \in T \setminus \{\varphi_n\}_{n\in\N}$
\end{tcolorbox}
\begin{adjustwidth}{0.07\textwidth}{}
    Al ser, $T$ ortonormal, $\{f\} \cup \{\varphi_n\}_{n\in\N}$ ha de serlo también. De este modo, $\langle f, \varphi_n\rangle = 0$ $\forall n \in \N$. Aplicando la hipótesis, tenemos que $f \muae 0$. Sabemos por el primer ejercicio de esta sección que todo sistema ortonormal es linealmente independiente, lo que entra en contradicción con $f \muae 0$.
\end{adjustwidth}
\begin{tcolorbox}[Implication-number]
    $c \Rightarrow a$  \hspace{3mm} Supongamos $f, g \in \mathcal{L}_2([0,2\pi])$ tales que $\langle f, \varphi_n\rangle = \langle g, \varphi_n\rangle$ $\forall n \in \N$.
\end{tcolorbox}
\begin{adjustwidth}{0.07\textwidth}{}
    Supongamos además que $f$ y $g$ no son iguales en casi todo punto; es decir, $f-g \neq 0$ en $L_2([0,2\pi])$.

    \vspace{2mm} Sea $T = \{\varphi_n\}_{n\in\N}$ Aplicando la hipótesis, para $n \in \N$ cualquiera,
    $$\langle f-g, \varphi_n\rangle = \langle f,\varphi_n\rangle - \langle g, \varphi_n\rangle = 0$$
    \indent De este modo, $f-g$ es un vector no nulo ortogonal a todos los de $T$. Por tanto, normalizando, $\left\{\frac{f-g}{||f-g||}\right\} \cup T$ es un sistema ortonormal. Aplicando la hipótesis de maximalidad, ha de cumplirse $\frac{f-g}{||f-g||} \muae \varphi_j$ para cierto $j\in\N$.

    \vspace{2mm} Como $T$ es ortonormal, tenemos que:
    $$||f-g||\cdot ||\varphi_j||^2 = \langle f-g, \varphi_j\rangle = \langle f, \varphi_j\rangle - \langle g, \varphi_j\rangle \neq 0$$
    Hemos llegado a una contradicción.
\end{adjustwidth}

\vspace{4mm} (2) Como hemos demostrado la caracterización en el apartado anterior, suponer que el sistema ortonormal $T$ verifica (c) es equivalente a suponer que verifica (a).
\vspace{2mm}
\begin{adjustwidth}{0.07\textwidth}{}
    Por el resultado 4.1.5 de los apuntes de Teoría, sabemos que $s := \sum_{k=0}^{\infty}\langle f,\varphi_k\rangle \varphi_k$ converge y está bien definida. Sea $j \in \N$ cualquiera,
    $$\langle s,\varphi_j\rangle = \left\langle \sum_{k=0}^{\infty}\langle f, \varphi_k\rangle \varphi_k, \varphi_j \right\rangle = \sum_{k=0}^{\infty} \langle f,\varphi_k \rangle\cdot \langle \varphi_k, \varphi_j\rangle = \langle f, \varphi_j\rangle$$
  Por tanto, en vista de la afirmación (a), es claro que $f \muae s$. Por Análisis Matemático I, sabemos que la norma es una aplicación continua. De este modo,
  $$\lim_{n\to\infty} \left|\left|f - \sum_{k=0}^{n}\langle f, \varphi_k\rangle \varphi_k \right|\right| = \left|\left|f - \sum_{k=0}^{\infty} \langle f, \varphi_k\rangle \varphi_k \right|\right| = 0$$

  \vspace{4mm} La convergencia se da en norma, pero no tiene por qué ocurrir que $f = s$. Por tanto, sí sería una base de $L_2(I)$, pero no de $\mathcal{L}_2(I)$ al no ser este último un espacio de Banach.
\end{adjustwidth}

\newpage
\chapter{Funciones de variación acotada}
\hspace{3mm}
Sea \(f:[a,b]\longrightarrow\mathbb{R}\) una función definida sobre un intervalo compacto no degenerado y sea \(P:=\{a=t_0<t_1<\dots< t_{n-1}<t_n=b\}\) una partición finita de \([a,b]\). Llamamos variación de \(f\), semi-variación positiva de \(f\) y semi-variación negativa de \(f\) respecto de \(P\) a los valores respectivos
\[
V(f,P):=\sum_{i=1}^n |f(t_i)-f(t_{i-1})|,
\]
\[
V^+(f,P):=\sum_{i=1}^n (f(t_i)-f(t_{i-1}))^+,
\]
\[
V^-(f,P):=\sum_{i=1}^n (f(t_i)-f(t_{i-1}))^-,
\]
donde, para \(x\in\mathbb{R}\), \(x^+:=\max\{x,0\}\) y \(x^-:=\max\{-x,0\}\).

Como de costumbre, denotaremos por \(\mathcal{P}([a,b])\) al conjunto de todas las particiones finitas de \([a,b]\). Se llama variación de \(f\) al valor
\[
V(f):=\sup\{V(f,P):P\in\mathcal{P}([a,b])\}.
\]

Si \(V(f)<\infty\), se dice que \(f\) es de variación acotada. Las semi-variaciones positiva y negativa de \(f\) se definen como
\[
V^+(f):=\sup\{V^+(f,P):P\in\mathcal{P}([a,b])\},
\qquad
V^-(f):=\sup\{V^-(f,P):P\in\mathcal{P}([a,b])\}.
\]

\vspace{6mm}
\result{Ejercicio 1}
\hspace{3mm} Demuestra que una función \(f:[a,b]\longrightarrow\mathbb{R}\) es de variación acotada si y sólo si sus semi-variaciones positiva y negativa son ambas finitas.

\newpage \dem \vspace{2mm} \newline \indent
Sea $P:=\{a=t_0<t_1<\dots< t_{n-1}<t_n=b\} \in \mathcal{P}([a,b])$ cualquiera, tenemos:
$$V(f,P):=\sum_{i=1}^n |f(t_i)-f(t_{i-1})| = \sum_{i=1}^n \Big(f(t_i)-f(t_{i-1})\Big)^+ +\Big(f(t_i)-f(t_{i-1})\Big)^- = V^+(f,P) + V^-(f,P)$$
Tomando supremos, llegamos a que $V(f) \leq V^+(f) + V^-(f)$. Por tanto, si las semi-variaciones positiva y negativa son finitas, también tendrá que serlo $V(F)$.

\vspace{2mm} En cuanto a la otra implicación, supongamos ahora que $V(f)^+ = \infty$ para ver que $V(f) = \infty$ (el caso $V^-(f) = \infty$ es análogo). Sea $K \in \R$; por hipótesis, existe $P \in \mathcal{P}([a,b])$ tal que $V^+(f,P) > K$. Por tanto, \vspace{-2ex}
$$V(f,P) = V^+(f,P) + V^-(f,P) \geq V^+(f,P) > K$$

\vspace{6mm}
\result{Ejercicio 2}
\hspace{3mm} Sea \(f:[a,b]\to\mathbb{R}\) una función de variación acotada tal que \(f(a)=0\). Demuestra que $f=g-h$, donde
$$g(x)=V^{+}\bigl(f;[a,x]\bigr),\qquad h(x)=V^{-}\bigl(f;[a,x]\bigr)$$

\vspace{4mm} \dem \vspace{2mm} \newline \indent
Fijamos $x \in [a,b]$ cualquiera. Sea $P = \{a = t_0 < \ldots < t_n = x\} \in \mathcal{P}([a,x])$ cualquiera, se cumple:
\begin{flalign*}
  V^+(f_{|[a,x]}, P)& - V^-(f_{|[a,x]}, P) = \sum_{i=1}^{n} \Big(f(t_i) - f(t_{i-1})\Big)^+ - \Big(f(t_i) - f(t_{i-1})\Big)^- =&&\\ 
  &=\sum_{i=1}^{n}f(t_i) - f(t_{i-1}) = f(x) - f(a) = f(x)
\end{flalign*}
Se tiene por ser telescópica la suma. Tomando supremos (podemos hacerlo adecuadamente al ser de variación acotada) se llega al resultado.

\result{Ejercicio 3}
\hspace{3mm} Demuestra que toda función de variación acotada $f$ sobre un intervalo compacto $[a,b]$ puede descomponerse como $f = g_1 - g_2$, donde $g_1$ y $g_2$ son dos funciones crecientes y acotadas en $[a,b]$.

\vspace{4mm} \dem \vspace{2mm} \newline \indent
Por el ejercicio anterior, sabemos que para las siguientes funciones,
\begin{align*}
    g_1(x) = V^+(f_{|[a,x]}) + f(a) && g_2(x) = V^-(f_{|[a,x]})
\end{align*}
se cumple que $f(x) = g_1(x) - g_2(x)$. Veamos que $g_2$ es monótona (el caso $g_1$ es análogo).

\vspace{2mm} Sean $x,y \in [a,b]$ con $x < y$, veamos que $g_2(x) \leq g_2(y)$. \newline \noindent Sea $P = \{a = t_0<\ldots<t_n=x\} \in \mathcal{P}([a,x])$, consideramos $\hat{P} := P \cup \{y\} \in \mathcal{P}([a,y])$. Así,
\begin{flalign*}
  V^-(f_{|[a,x]}&, P) = \sum_{i=1}^{n} \Big(f(t_i) - f(t_{i-1})\Big)^{-} \leq \Big(f(y) - f(x)\Big)^- +\sum_{i=1}^{n} \Big(f(t_i) - f(t_{i-1})\Big)^{-} =&&\\[1ex]
  &= \sum_{i=1}^{n+1}\Big(f(t_i)- f(t_{i-1})\Big)^- = V^-(f_{|[a,y]}, \hat{P})
\end{flalign*}
En vista del primer ejercicio de esta sección, al ser $f$ de variación acotada, también lo son $g_1$ y $g_2$ (luego son acotadas). Tomando supremos podemos ver que son crecientes.

\vspace{6mm}
\result{Ejercicio 4}
\hspace{3mm} Demuestra que si una función $f$ es de variación acotada, entonces todas sus discontinuidades son de salto finito o evitables.

\vspace{4mm} \dem \vspace{2mm} \newline \indent
Por el ejercicio anterior, sabemos que es posible descomponer $f$ como $f = g_1 - g_2$ con $g_1, g_2$ funciones crecientes acotadas. Basta ver que las discontinuidades de una función $g$ creciente son se salto finito. Para ello, veamos que existen siempre los límites laterales de $g$.

\vspace{2mm} Fijado $x$ cualquiera, consideramos el siguiente conjunto:\newline \noindent $\mathcal{A} := \{g(t) : t < x\}$., que está acotado superiormente por ser $g$ creciente. De este modo, podemos considerar $A := \sup \mathcal{A}$.

\vspace{2mm} Por definición de supremo, para $\varepsilon > 0$ cualquiera, existe $\delta > 0$ tal que: 
$$g(x-\delta) > A - \varepsilon$$
Al ser $g$ creciente, para cada $t \in (x-\delta, x)$, se cumple:
\begin{align*}
  A - \varepsilon < g(x-\delta) \leq g(t) \leq A &&
  -A \leq -A < \varepsilon - A
\end{align*}
De este modo, sumando, $-\varepsilon < g(t) - A < \varepsilon$. Tenemos que existe el límite izquierdo. Análogamente, podemos comprobar la existencia del derecho.

\vspace{2mm} Volviendo al problema original, tenemos $f = g_1 - g_2$ con $g_1$ y $g_2$ monótonas y acotadas. Por tanto, todas sus discontinuidades han de ser de salto finito. Al pasar a la resta, podrían producirse además discontinuidades evitables. Por ejemplo,
\begin{align*}
    g_1(x) = \begin{cases}
      0 &\text{ si } x < 0\\
      2 &\text{ si } x \geq 0
    \end{cases} &&
    g_1(x) = \begin{cases}
      0 &\text{ si } x \leq 0\\
      1 &\text{ si } x > 0
    \end{cases} &&
    f(x) = \begin{cases}
      0 &\text{ si } x < 0\\
      2 &\text{ si } x = 0\\
      1 &\text{ si } x > 0  
    \end{cases} &&
\end{align*}
Toda discontinuidad de $f$ ha de corresponderse con una discontinuidad de $g_1$ o de $g_2$ (o de ambas a la vez), luego han de ser de salto finito o evitables.

\newpage
\chapter{Fallos en las condiciones de Dini o de Jordan}
\result{Ejercicio 1}
\hspace{3mm} Consideremos la siguiente función:
\begin{align*}
    f: [-\pi, \pi] \longrightarrow \R &&
    x \longmapsto f(x) = \begin{cases}
      x\sin\left(\frac{1}{x}\right) &\text{ si } x \neq 0 \\
      0 &\text{ si } x \neq 0      
    \end{cases}
\end{align*}
extendida por periodicidad $2\pi$ en $\R$. Demuestra que $f$ es continua en $\R$, y que en $x = 0$ no se verifica la condición de Jordan, pero sí la de Dini.

\vspace{4mm} \dem \vspace{2mm} \newline \indent
Para $x = 0$, $\mlim{t\to 0} \hspace{1mm} f(t) = \mlim{t\to 0} \hspace{1mm} t \sin\left(\frac{1}{t}\right) = 0 = f(x)$: producto de un infinitésimo por una función acotada.

\vspace{2mm} En el resto de $[-\pi, \pi]$, $f$ es claramente continua al ser producto de funciones continuas. Finalmente, por ser una función con simetría par, es continua en la frontera de las expansiones por periodicidad:
$$\lim_{x\to \pi^-}f(x) = f(\pi) = \pi \sin\left(\frac{1}{\pi}\right) = -\pi \sin\left(-\frac{1}{\pi}\right) = f(-\pi) = \lim_{x \to -\pi^+}f(x)$$

\vspace{4mm} Para ver que no se cumple la condición de Jordan, hemos de comprobar que $f$ no es de variación acotada en $[-\varepsilon, \varepsilon]$ para ningún $\varepsilon > 0$. Es decir,
$$\forall \hspace{1mm} \varepsilon > 0, \hspace{1mm} \forall \hspace{1mm} K \in \R \hspace{2ex} \exists \hspace{1mm} P \in \mathcal{P}([-\varepsilon, \varepsilon]) : \hspace{2mm}  V(f,P) > K$$

Consideramos la siguiente sucesión: $(a_n)_{n\in\N} = \left(\frac{2}{n\pi}\right)_{n\in\N}$. Sea $\varepsilon > 0$, sea $K \in \R$. Por la propiedad arquimediana, existe $n_0 \in \N$ tal que $a_n \in [-\varepsilon, \varepsilon]$ para todo $n \geq n_0$. Dado $n \geq n_0$, evaluamos $f$ en un término de la sucesión:
$$f(a_n) = \frac{2}{n\pi} \sin\left(\frac{\pi}{2}\cdot n\right) = \frac{2}{\pi} \cdot \frac{1}{n} \cdot b_n \hspace{4ex} \text{ con } b_n = \begin{cases}
  0 &\text{ si } \mod_2(n) = 0\\[-1ex]
  1 &\text{ si } \mod_4(n) = 1\\[-1ex]
  -1 &\text{ si } \mod_4(n) = 3
\end{cases}$$

\newpage
Comparando con la expresión de la variación de $f$ en una partición, tenemos que:
$$\sum_{k=n_0+1}^{\infty}|f(a_k) - f(a_{k-1})| \geq \sum_{k=n_0 + 1}^{\infty}\frac{2}{\pi} \cdot \frac{1}{k-1} > \sum_{k=n_0}^{\infty} \frac{2}{\pi} \cdot \frac{1}{k-1} = \infty$$
Por tanto, podemos tomar un subconjunto finito de la sucesión contenido en $[-\varepsilon, \varepsilon]$ tal que la variación que induzca cualquier partición que lo contenga sea mayor que $K$. Hemos comprobado que no se cumple la condición de Jordan.

\vspace{4mm} Veamos ahora que sí se verifica la condición de Dini. Como ya hemos comprobado antes, la función $f$ tiene simetría par. Por tanto, para $t > 0$ se tiene:
$$g(t) := \frac{f(t) + f(-t)}{2} = \frac{2f(t)}{2} = f(t)$$
Tomando límites, $g(0^+) = \mlim{t\to 0^+} \hspace{1mm} g(t) = 0$, como ya estudiamos antes. De este modo, sea $\delta \in (0, \pi)$ cualquiera,
$$\frac{g(t) - g(0^+)}{t} = \frac{f(t)}{t} = \begin{cases}
  \sin\left(\frac{1}{t}\right) &\text{ si } t \neq 0\\
  0 &\text{ si } t = 0\\
\end{cases} \hspace{1ex} \in L_1([0,\delta])$$
Es $L_1([0,\delta])$ en virtud del criterio de integración de Lebesgue, pues la función es acotada y tiene un conjunto de discontinuidades de medida nula. Hemos comprobado que se cumple la condición de Dini.

\vspace{6mm}
\result{Ejercicio 2}
\hspace{3mm} Consideremos la siguiente función:
\begin{align*}
    f: [-\pi, \pi] \longrightarrow \R &&
    x \longmapsto f(x) = \begin{cases}
      \frac{1}{\log\left(\frac{1}{|x|}\right)} &\text{ si } x \neq 0 \\
      0 &\text{ si } x \neq 0      
    \end{cases}
\end{align*}
extendida por periodicidad $2\pi$ en $\R$. Demuestra que $f$ es continua en $\R$, y que en $x = 0$ no se verifica la condición de Dini, pero sí la de Jordan.

\vspace{4mm} \dem \vspace{2mm} \newline \indent
En primer lugar, veamos que es continua. Como $\mlim{x\to\infty} \hspace{1mm} \log(x) = \infty$, tenemos que $\lim_{x\to 0} f(x) = 0 = f(0)$. Además, al tener $f$ simetría par tenemos que:
$$\lim_{x\to\pi^-}f(x) = f(\pi) = f(-\pi) = \lim_{x\to -\pi^+}$$
Por tanto, $f$ es continua en $\R \setminus\{1\}$.

\vspace{2mm} Veamos que $f$ sí cumple la condición de Jordan. Sea $\varepsilon \in (0, \pi)$ cualquiera, tenemos que $f$ es monótona en $[-\varepsilon, 0]$ y en $[0, \varepsilon]$, luego es de variación acotada. Como es continua en $\R$, es $L_1([0,2\pi])$. Por tener simetría par,
$$\lim_{t\to 0^+} \frac{f(t)+f(-t)}{2} = \lim_{t\to 0^+} f(t) = f(0) = 0$$

\vspace{4mm} Veamos ahora que no cumple la condición de Dini. Reutilizando lo explicado para la Condición de Jordan, fijamos $\delta > 0$ arbitrariamente pequeño. Se tiene:
\begin{align*}
    g(t) = \frac{f(t)+ f(-t)}{2} = f(t) && \frac{g(t) - g(0^+)}{t} = \frac{g(t)}{t} = \frac{1}{t\cdot \log\left(\frac{1}{|t|}\right)}
\end{align*}
Para $t > 0$ suficientemente pequeño, $\frac{1}{t} > e$, luego $\log\left(\frac{1}{t}\right) > 1$. De este modo,
$$\left|\frac{1}{t}\cdot \frac{1}{\log\left(\frac{1}{t}\right)}\right| \geq \left|\frac{1}{t}\right| \notin L_1\left(\left[0, \delta\right]\right)$$
Por tato, no se satisface la condición de Dini.

\vspace{6mm}
\result{Ejercicio 3}
\hspace{3mm} Consideremos la función $h(x) = f(x) \cdot \sin^2\left(\frac{1}{x}\right)$, donde $f$ es la función del ejercicio anterior. Si la extendemos por periodicidad en $\R$, ¿dónde es continua? ¿Satisface la condición de Jordan? ¿Y la de Dini?
\begin{align*}
    h: [-\pi, \pi] \longrightarrow \R &&
    x \longmapsto h(x) = \begin{cases}
      \frac{\sin^2\left(\frac{1}{x}\right)}{\log\left(\frac{1}{|x|}\right)} &\text{ si } x \neq 0 \\
      0 &\text{ si } x \neq 0      
    \end{cases}
\end{align*}

\vspace{4mm} \dem \vspace{2mm} \newline \indent
En primer lugar, tenemos que la función es continua en $0$, pues $\mlim{x \to 0} \hspace{1mm} h(x) = 0 = h(0)$ al ser $f$ un infinitésimo y $\sin^2\left(\frac{1}{x}\right)$ una función acotada. Una vez más, la función tiene simetría par, luego:
$$\lim_{x\to\pi^-}h(x) = h(\pi) = h(-\pi) = \lim_{x\to -\pi^+}h(x)$$
Por tanto, tenemos que $h$ es continua en $\R \setminus \{1\}$.

\vspace{2mm} Veamos que no verifica la condición de Jordan. Consideramos la siguiente sucesión: $(a_n)_{n\in\N} = \left(\frac{2}{n\pi}\right)_{n\in\N}$. Para $\varepsilon > 0$ cualquiera, la sucesión estará contenida en $[-\varepsilon,\varepsilon]$ a partir de cierto término $n_0$. Dado $n \geq n_0$, comparando con la variación de $h$,
$$\sum_{k=n_0 + 1}^\infty |f(a_k) - f(a_{k-1})| \geq \sum_{k=n_0}^{\infty} \frac{1}{\log\left(\frac{\pi}{2}\cdot k\right)} = \infty$$
Como la serie diverge, podemos tomar sumas parciales arbitrariamente grandes. Así, para cada $K \in \R$ es posible tomar $P \in \mathcal{P}([-\varepsilon,\varepsilon])$ tal que $V(h,P) > K$. Concluimos que no cumple la condición de Jordan.

\vspace{4mm}
Veamos que no cumple la condición de Dini. Sea $\delta > 0$ cualquiera, sabemos que:
\vspace{-4ex}
\begin{align*}
    g(t) = \frac{f(t)+ f(-t)}{2} = f(t) &&
    \hat{g}(t) := \frac{g(t) - g(0^+)}{t} = \frac{g(t)}{t} = \frac{\sin^2\left(\frac{1}{t}\right)}{t\cdot \log\left(\frac{1}{|t|}\right)}
\end{align*}
\vspace{-1ex}
Como $\left|\sin^2\left(\frac{1}{t}\right)\right| \leq 1$ y para $t$ suficientemente pequeño tenemos que $|f(t)| \leq 1$. Entonces, se cumple:
$$|\hat{g}(t)| \leq \frac{1}{t} \notin L_1([0,\delta])  $$
Hemos comprobado que no cumple la condición de Dini.
\end{document}